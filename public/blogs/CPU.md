- [ ] CPU #Complete
---

## Overview

Central Processing Unit (CPU) is the heart and/or brain of a computer. *The CPU is the processor*, it is in charge of executing tasks by constantly solving the mathematical problems.

The purpose of a CPU is to *read*, *process*, and *move* information in the form of [[Bit vs Bytes|bits]]. The CPU performs calculations, makes logical comparisons and moves data up to billions of times per second. It works by executing simple instructions one at a time, triggered by a [[CPU#Clock|master timing system]] that runs the whole computer.

The terms "CPU" and "processor" are often used interchangeably in many contexts. Traditionally, a CPU or processor referred to a single core that could execute one task at a time.

## Instructions

All CPUs have an instruction set - a list of actions the processor performs, including adding numbers, comparing two pieces of data and moving data into the CPU. The software you run on your computer consists of millions of the CPU's instructions laid out in a sequence; instructions are very simple operations, so the CPU performs many of them to accomplish meaningful tasks. Some CPUs, such as the ones used in desktop PCs, use the same instruction set, allowing them to run the same software. However, CPUs outside a that family may use different instructions; an iPad's CPU, for example, has different instructions than one running a Windows-based laptop, and hence, you need different software to run on each.

If you're familiar with [[Containers, VMs and Serverless|VMs]] and [[Docker]] you may think this is why they exist - to work on different CPUs. Whilst this is partially correct and having a Windows VM allows for usage on a Mac system, there are other reasons along the way such as OS handling (for VMs), and having standalone processing.

Instructions include:

-   Arithmetic such as **add*** and ***subtract***
-   Logic instructions such as **and**, **or***, and **not***
-   Data instructions such as **move***, ***input**, **output***, **load**, and **store***
-   Control Flow instructions such as **go to***, ***if … go to**, **call**, and ***return***
-   Notify CPU that the program has ended **Halt***

Instruction are provided to the computer using assembly language, generated by a compiler, or are interpreted in some high level languages.

<img src="https://www.freecodecamp.org/news/content/images/2022/04/arm-1.png" alt="Learn Assembly Language Programming with ARM" width="350" height="300" />

For example, [[JavaScript Processing|JavaScript gets processed into machine language]] to be run on the CPU. 

These instruction are hardwired inside CPU. 

### How an Instruction Gets Executed
TO DO:
 - https://www.freecodecamp.org/news/how-does-a-cpu-work/

## Clock

In one ***clock cycle*** computers can perform one instruction, but modern computers can perform more than one. A group of instructions a computer can perform is called an **instruction set**.

A timing circuit called a clock sends electrical pulses to the CPU. Depending on the processor, the clock may run at speeds ranging from hundreds of thousands to billions of cycles per second.  So for example, *the CPU could process hundreds of thousands to billions of instructions per second, and that is why having better CPUs will make the device run quicker.* The pulses drive activity inside the CPU; because other circuits depend on the same clock, it keeps complex events in the computer synchronised.

### The CPU Processing System Cycle

**The clock speed is how many times per second a CPU completes a clock (or work) cycle.** For example, a modern cheap INTEL I3 processor can complete four billion cycles per second, per core.

The process goes like this:
- Fetch an instruction from Random Access Memory ([[Memory (RAM)|RAM]])
- Decode it
- and execute it

The above would happen X times per second, and the better the CPU, the more times this could happen.

> Note: This clock cycle mentioned above is referring to one core, to improve CPU performance it can have numerous [[CPU#CPU Cores|cores]].

## A Processors Parts

A processor has two parts:

- **Control Unit** - CU
- **Arithmetic and logic unit** - ALU

### Control Unit

The CPU contains a control unit that coordinates activities among the processor's other working parts. The control unit breaks each instruction down into a set of actions and directs the CPU's various subsystems to carry out the actions. For example, the control unit could direct the ALU to multiply two numbers together and then add a third number to the result.

### ALU (arithmetic and Control unit)

Arithmetic and logical unit ALU as name suggest does all the arithmetic and logical computations. ALU performs the operations like addition, subtraction. ALU consists of logic circuitry or logic gates which performs these operations.

Most logic gates take in two input and produces one output.

Below is an example of half adder circuit which takes in two inputs and outputs the result. Here A and B are the input, S is the output and C is the carry.

![[CPU Gate.png]]

## Memory (RAM)

The CPU chip has a limited amount of very fast memory. It has a set of storage areas called registers upon which the ALU acts directly. For example, the ALU can add the number in register 2 to the contents of register 1 quickly. The CPU also keeps recently-used instructions and data in cache that improves the computer's efficiency. In a program that multiplies a price by a quantity, for example, the CPU looks for these numbers in its cache memory. If it finds them, this saves the processor the extra work of retrieving the numbers from memory chips outside the CPU.

## CPU Cores

A core is a physical component of a CPU that is capable of performing tasks. A CPU can have more than one core, this can lead to performance gain of the device, so numerous cores can synonymous to a multicore processor. A multicore processor is independent processors put together in the same circuit with their own set of instructions and programs. Think of it having numerous processors in one. Although the core is a standalone processor, it can share some of the same resources as the other processors such as cache.

Traditionally, a CPU or processor referred to a single core that could execute one task at a time. However, with the advent of multicore processors, each of these cores is effectively a processor in its own right—they can each execute instructions independently of the others. *So in modern usage, when we say a "processor," it could mean a single core within a multicore CPU, or it could refer to the CPU as a whole, depending on the context.*

Each CPU (core) executes a single process at a time. However, multitasking allows each processor to [switch](https://en.m.wikipedia.org/wiki/Context_switch "Context switch") between tasks that are being executed without having to wait for each task to finish ([preemption](https://en.m.wikipedia.org/wiki/Preemption_(computing) "Preemption (computing)")). In a strictly technical sense, **a single core can only execute instructions from only one [[CPU#What is Threading?|thread]] of one [[Process|process]] at a time.** However, it's important to remember that modern operating systems use a technique called "time slicing" or "context switching" to give the illusion of running multiple processes simultaneously.

With time slicing, the operating system switches between different threads very rapidly (many times per second), assigning each a small slice of processing time. After each slice of time, the current state of the process (including things like register contents and program counters) is saved, and the state of the next process is loaded. This happens so quickly that, to a human observer, it appears as though multiple processes are running at the same time, even on a single-core CPU.

**Performance**: Theoretically, more cores could lead to performance gains because tasks can be distributed among different cores. However, this doesn't mean that a 10-core processor would be able to handle 10 times the number of cycles as a single-core processor with the same clock speed. The actual performance gain depends on several factors, including the efficiency of the cores, the architecture of the processor, and the nature of the tasks being performed. Not all tasks can be parallelized (divided among multiple cores) effectively.

**Shared Resources**: Cores in a multicore processor often do share some resources. This typically includes some level of the processor's cache, although each core also typically has its own dedicated level of cache. Sharing cache can help with efficiency, but it can also potentially lead to conflicts and performance issues if not managed correctly.

### [[Concurrency vs Parallelism|Concurrency]] On Single-core Vs Multicore

On a single-core CPU, concurrency is more about multitasking—giving the illusion that multiple tasks are happening simultaneously through time-slicing. On multicore CPUs, concurrency allows for actual parallel execution where multiple tasks can genuinely run at the same time on different cores.

## What is Threading?

There are two types of [[Threads|threads]] within the operating system, this is *user level threading (ULT)* and *[[Kernel|kernel]] threading (KLT)*. A thread is the smallest possible execution that exists within a process, essentially you can consider it a piece of code that an application will run. A CPU can allow numerous threads to be run in parallel or concurrently, it depends on the architecture of the CPU. When a process has numerous possible tasks happening at the same time, such as playing sounds and updating input, these tasks would usually be split across different threads (it's up to the developer on how the program handles numerous tasks so it may not always be in separate threads). Threading in language dependant, meaning how you allocate more than one thread is unique per programming language. Some languages are one thread by default such as JavaScript. [[Why JavaScript is Single Threaded|JavaScript is single threaded]] by default and the utilisation of [[Asynchronous JavaScript|asynchronous JavaScript]] and [[Web Workers|web workers]] to enable the language to be run in more than thread.

## Logical Cores

A logical core exists within a physical core. Logical cores arose from the technology from Simultaneous Multithreading (SMT), or Hyper-Threading (HTT) from Intel's CPU - it can be seen as a 'virtual core'. As of 2023, the typical logical cores is two per physical core and that means, if a PC has 8 cores, the total logical cores would be 16. Logical cores are the result allowing numerous threads to run in parallel (the number of logical cores is dependant on the CPU itself). If a logical core exists, that is, for example two logical cores inside a single core CPU, it will allow up to two threads to run in parallel, whereas if there was a third, it would require the third thread to now run concurrently. A CPU will have a set number of logical cores and it's up to the software to utilise them.

It is up to the CPU itself to allocate logical cores. The number of logical cores a physical core can have is determined by the degree of simultaneous multithreading (SMT) the CPU architecture supports. As of 2021:

1. **Intel's Hyper-Threading:** The most common implementation of SMT in consumer-grade CPUs, typically doubles the number of logical cores relative to physical cores. That is, each physical core provides two logical cores.

3. **AMD's Ryzen processors:** These use a similar 2-thread-per-core SMT approach as Intel, doubling the logical core count relative to the physical cores.

4. **IBM's POWER CPUs:** Some of IBM's POWER processors support up to 8 threads per core. This means for every physical core, there can be up to 8 logical cores.

4. **Others:** There might be other specialized architectures or experimental setups that support different degrees of SMT, but 2-thread-per-core is the most common in consumer devices.

However, just increasing the number of logical cores per physical core doesn't linearly scale performance. There's a point of diminishing returns since the physical resources (like execution units, cache, etc.) of the core still have to be shared among all its threads. As of now, 2-thread SMT (resulting in 2 logical cores per physical core) strikes a good balance for general-purpose consumer CPUs, but specific applications and workloads can benefit from higher degrees of SMT.

## Operating Specification

While the CPU's architecture (e.g., x86 vs ARM) is a major reason for software being platform-specific, the operating system also plays a crucial role. The OS provides the fundamental APIs and services for tasks like file access, network communication, and, relevantly, memory management. Different OSes may have different memory management schemes and system call interfaces, making them distinct in how software interacts with them. RAM as a hardware component is generally the same (it stores data), but how the data is managed, accessed, and organized is where differences arise, based on both the CPU and the OS.

## The Library Example
(*By Vince*)

Think of a library where you're working. Your brain is the CPU; the workings on top of your desk is the RAM. you're recalling work and the surrounding library in the storage. If you need to get information that is new, maybe unused, go to storage to get it and go back to your desk. If you're working things out; it's in your brain. If you're recalling information - go to RAM. (Cache can be in draws in the desk).

## Further Reading

- [CPU Cores, Logical processors and threads and the comparison between having more or less power etc.](https://www.cgdirector.com/cpu-cores-vs-logical-processors-threads/)
---

> Path: /Users/beam/Documents/Obsidian Vault/Coding/General/How computers work/CPU.md
